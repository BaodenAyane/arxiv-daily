{"Bandits": {"2503.03023": "|**2025-03-04**|**Quantum Non-Linear Bandit Optimization**|Zakaria Shams Siam et.al.|[2503.03023](http://arxiv.org/abs/2503.03023)|null|\n", "2503.02043": "|**2025-03-03**|**Constrained Linear Thompson Sampling**|Aditya Gangrade et.al.|[2503.02043](http://arxiv.org/abs/2503.02043)|null|\n", "2503.00929": "|**2025-03-02**|**Parameter-Adaptive Dynamic Pricing**|Xueping Gong et.al.|[2503.00929](http://arxiv.org/abs/2503.00929)|null|\n", "2503.00565": "|**2025-03-01**|**Semi-Parametric Batched Global Multi-Armed Bandits with Covariates**|Sakshi Arya et.al.|[2503.00565](http://arxiv.org/abs/2503.00565)|null|\n", "2503.00419": "|**2025-03-01**|**Heavy-Tailed Linear Bandits: Huber Regression with One-Pass Update**|Jing Wang et.al.|[2503.00419](http://arxiv.org/abs/2503.00419)|null|\n", "2502.17175": "|**2025-02-24**|**Linear Bandits on Ellipsoids: Minimax Optimal Algorithms**|Raymond Zhang et.al.|[2502.17175](http://arxiv.org/abs/2502.17175)|null|\n", "2502.12528": "|**2025-02-20**|**Contextual Linear Bandits with Delay as Payoff**|Mengxiao Zhang et.al.|[2502.12528](http://arxiv.org/abs/2502.12528)|null|\n", "2502.08870": "|**2025-02-13**|**When and why randomised exploration works (in linear bandits)**|Marc Abeille et.al.|[2502.08870](http://arxiv.org/abs/2502.08870)|null|\n", "2502.07514": "|**2025-02-11**|**A Near-optimal, Scalable and Corruption-tolerant Framework for Stochastic Bandits: From Single-Agent to Multi-Agent and Beyond**|Zicheng Hu et.al.|[2502.07514](http://arxiv.org/abs/2502.07514)|null|\n", "2502.07397": "|**2025-02-11**|**Bandit Optimal Transport**|Lorenzo Croissant et.al.|[2502.07397](http://arxiv.org/abs/2502.07397)|null|\n", "2502.08077": "|**2025-02-12**|**Cascading Bandits Robust to Adversarial Corruptions**|Jize Xie et.al.|[2502.08077](http://arxiv.org/abs/2502.08077)|null|\n", "2503.02952": "|**2025-03-04**|**A Theoretical Model for Grit in Pursuing Ambitious Ends**|Avrim Blum et.al.|[2503.02952](http://arxiv.org/abs/2503.02952)|null|\n", "2503.02735": "|**2025-03-04**|**Clustered KL-barycenter design for policy evaluation**|Simon Weissmann et.al.|[2503.02735](http://arxiv.org/abs/2503.02735)|null|\n", "2503.02428": "|**2025-03-04**|**Tight Gap-Dependent Memory-Regret Trade-Off for Single-Pass Streaming Stochastic Multi-Armed Bandits**|Zichun Ye et.al.|[2503.02428](http://arxiv.org/abs/2503.02428)|null|\n", "2503.01324": "|**2025-03-03**|**MAB-Based Channel Scheduling for Asynchronous Federated Learning in Non-Stationary Environments**|Zhiyin Li et.al.|[2503.01324](http://arxiv.org/abs/2503.01324)|null|\n", "2503.01215": "|**2025-03-03**|**Architectural and Inferential Inductive Biases For Exchangeable Sequence Modeling**|Daksh Mittal et.al.|[2503.01215](http://arxiv.org/abs/2503.01215)|**[link](https://github.com/namkoong-lab/inductive-biases-exchangeable-sequence)**|\n", "2503.01163": "|**2025-03-03**|**Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers**|Rin Ashizawa et.al.|[2503.01163](http://arxiv.org/abs/2503.01163)|null|\n", "2503.01919": "|**2025-03-01**|**Reinforcement learning with combinatorial actions for coupled restless bandits**|Lily Xu et.al.|[2503.01919](http://arxiv.org/abs/2503.01919)|null|\n", "2503.04518": "|**2025-03-06**|**Leveraging priors on distribution functions for multi-arm bandits**|Sumit Vashishtha et.al.|[2503.04518](http://arxiv.org/abs/2503.04518)|null|\n", "2503.04010": "|**2025-03-06**|**Greedy Algorithm for Structured Bandits: A Sharp Characterization of Asymptotic Success / Failure**|Aleksandrs Slivkins et.al.|[2503.04010](http://arxiv.org/abs/2503.04010)|null|\n", "2503.05662": "|**2025-03-07**|**On Mitigating Affinity Bias through Bandits with Evolving Biased Feedback**|Matthew Faw et.al.|[2503.05662](http://arxiv.org/abs/2503.05662)|null|\n", "2503.05098": "|**2025-03-07**|**Empirical Bound Information-Directed Sampling for Norm-Agnostic Bandits**|Piotr M. Suder et.al.|[2503.05098](http://arxiv.org/abs/2503.05098)|null|\n", "2503.04855": "|**2025-03-06**|**A characterization of sample adaptivity in UCB data**|Yilun Chen et.al.|[2503.04855](http://arxiv.org/abs/2503.04855)|null|\n", "2503.08098": "|**2025-03-11**|**Locally Private Nonparametric Contextual Multi-armed Bandits**|Yuheng Ma et.al.|[2503.08098](http://arxiv.org/abs/2503.08098)|**[link](https://github.com/Karlmyh/LDP-Contextual-MAB)**|\n", "2503.08004": "|**2025-03-11**|**Multiplayer Information Asymmetric Bandits in Metric Spaces**|William Chang et.al.|[2503.08004](http://arxiv.org/abs/2503.08004)|null|\n", "2503.07877": "|**2025-03-10**|**Cost-Aware Optimal Pairwise Pure Exploration**|Di Wu et.al.|[2503.07877](http://arxiv.org/abs/2503.07877)|null|\n", "2503.07824": "|**2025-03-10**|**Pure Exploration with Feedback Graphs**|Alessio Russo et.al.|[2503.07824](http://arxiv.org/abs/2503.07824)|**[link](https://github.com/rssalessio/Pure-Exploration-with-Feedback-Graphs)**|\n", "2503.07555": "|**2025-03-10**|**Graph-Dependent Regret Bounds in Multi-Armed Bandits with Interference**|Fateme Jamshidi et.al.|[2503.07555](http://arxiv.org/abs/2503.07555)|null|\n", "2503.06101": "|**2025-03-08**|**ULTHO: Ultra-Lightweight yet Efficient Hyperparameter Optimization in Deep Reinforcement Learning**|Mingqi Yuan et.al.|[2503.06101](http://arxiv.org/abs/2503.06101)|null|\n", "2503.10386": "|**2025-03-14**|**Multi-objective Good Arm Identification with Bandit Feedback**|Xuanke Jiang et.al.|[2503.10386](http://arxiv.org/abs/2503.10386)|**[link](https://github.com/2015211217/MultiThresholdBandit)**|\n", "2503.10282": "|**2025-03-13**|**HyperArm Bandit Optimization: A Novel approach to Hyperparameter Optimization and an Analysis of Bandit Algorithms in Stochastic and Adversarial Settings**|Samih Karroum et.al.|[2503.10282](http://arxiv.org/abs/2503.10282)|null|\n", "2503.09755": "|**2025-03-12**|**Distributionally Robust Multi-Agent Reinforcement Learning for Dynamic Chute Mapping**|Guangyi Liu et.al.|[2503.09755](http://arxiv.org/abs/2503.09755)|null|\n", "2503.08961": "|**2025-03-11**|**Multiplayer Information Asymmetric Contextual Bandits**|William Chang et.al.|[2503.08961](http://arxiv.org/abs/2503.08961)|null|\n", "2503.08937": "|**2025-03-11**|**Beam Selection in ISAC using Contextual Bandit with Multi-modal Transformer and Transfer Learning**|Mohammad Farzanullah et.al.|[2503.08937](http://arxiv.org/abs/2503.08937)|null|\n", "2503.08896": "|**2025-03-11**|**Risk-sensitive Bandits: Arm Mixture Optimality and Regret-efficient Algorithms**|Meltem Tatl\u0131 et.al.|[2503.08896](http://arxiv.org/abs/2503.08896)|**[link](https://github.com/MeltemTatli/Risk-sensitive-Bandits-Arm-Mixture-Optimality)**|\n", "2503.08883": "|**2025-03-11**|**Imitation Learning of Correlated Policies in Stackelberg Games**|Kunag-Da Wang et.al.|[2503.08883](http://arxiv.org/abs/2503.08883)|null|\n", "2503.11209": "|**2025-03-18**|**Clustering Items through Bandit Feedback: Finding the Right Feature out of Many**|Maximilian Graf et.al.|[2503.11209](http://arxiv.org/abs/2503.11209)|null|\n", "2503.10836": "|**2025-03-13**|**Exploiting Concavity Information in Gaussian Process Contextual Bandit Optimization**|Kevin Li et.al.|[2503.10836](http://arxiv.org/abs/2503.10836)|null|\n", "2503.14796": "|**2025-03-19**|**A New Benchmark for Online Learning with Budget-Balancing Constraints**|Mark Braverman et.al.|[2503.14796](http://arxiv.org/abs/2503.14796)|null|\n", "2503.14663": "|**2025-03-18**|**Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction**|Anni Zhou et.al.|[2503.14663](http://arxiv.org/abs/2503.14663)|null|\n", "2503.13447": "|**2025-03-17**|**MetaScale: Test-Time Scaling with Evolving Meta-Thoughts**|Qin Liu et.al.|[2503.13447](http://arxiv.org/abs/2503.13447)|null|\n", "2503.13173": "|**2025-03-17**|**PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning**|Ori Peleg et.al.|[2503.13173](http://arxiv.org/abs/2503.13173)|**[link](https://github.com/oritalp/PAUSE)**|\n", "2503.12285": "|**2025-03-15**|**Bi-Criteria Optimization for Combinatorial Bandits: Sublinear Regret and Constraint Violation under Bandit Feedback**|Vaneet Aggarwal et.al.|[2503.12285](http://arxiv.org/abs/2503.12285)|null|\n", "2503.12020": "|**2025-03-15**|**Variance-Dependent Regret Lower Bounds for Contextual Bandits**|Jiafan He et.al.|[2503.12020](http://arxiv.org/abs/2503.12020)|null|\n", "2503.11991": "|**2025-03-15**|**Automation and Feature Selection Enhancement with Reinforcement Learning (RL)**|Sumana Sanyasipura Nagaraju et.al.|[2503.11991](http://arxiv.org/abs/2503.11991)|null|\n", "2503.16382": "|**2025-03-20**|**Sparse Nonparametric Contextual Bandits**|Hamish Flynn et.al.|[2503.16382](http://arxiv.org/abs/2503.16382)|null|\n", "2503.16107": "|**2025-03-20**|**Learn to Bid as a Price-Maker Wind Power Producer**|Shobhit Singhal et.al.|[2503.16107](http://arxiv.org/abs/2503.16107)|null|\n", "2503.15962": "|**2025-03-20**|**Information maximization for a broad variety of multi-armed bandit games**|Alex Barbier-Chebbah et.al.|[2503.15962](http://arxiv.org/abs/2503.15962)|null|\n", "2503.15581": "|**2025-03-19**|**Performance-bounded Online Ensemble Learning Method Based on Multi-armed bandits and Its Applications in Real-time Safety Assessment**|Songqiao Hu et.al.|[2503.15581](http://arxiv.org/abs/2503.15581)|**[link](https://github.com/liuzy0708/Awesome_OL)**|\n", "2503.18133": "|**2025-03-23**|**Beam Scheduling in Millimeter Wave Networks Using the Whittle Index**|Mandar R. Nalavade et.al.|[2503.18133](http://arxiv.org/abs/2503.18133)|null|\n", "2503.17674": "|**2025-03-22**|**MultiScale Contextual Bandits for Long Term Objectives**|Richa Rastogi et.al.|[2503.17674](http://arxiv.org/abs/2503.17674)|null|\n", "2503.16941": "|**2025-03-21**|**Sparse Additive Contextual Bandits: A Nonparametric Approach for Online Decision-making with High-dimensional Covariates**|Wenjia Wang et.al.|[2503.16941](http://arxiv.org/abs/2503.16941)|null|\n", "2503.16708": "|**2025-03-20**|**NeuroSep-CP-LCB: A Deep Learning-based Contextual Multi-armed Bandit Algorithm with Uncertainty Quantification for Early Sepsis Prediction**|Anni Zhou et.al.|[2503.16708](http://arxiv.org/abs/2503.16708)|null|\n", "2503.21498": "|**2025-03-27**|**Distributed Forgetting-factor Regret-based Online Optimization over Undirected Connected Networks**|Lipo Mo et.al.|[2503.21498](http://arxiv.org/abs/2503.21498)|null|\n", "2503.20975": "|**2025-03-26**|**Competitive Multi-armed Bandit Games for Resource Sharing**|Hongbo Li et.al.|[2503.20975](http://arxiv.org/abs/2503.20975)|null|\n", "2503.20968": "|**2025-03-26**|**Reinforcement Learning for Efficient Toxicity Detection in Competitive Online Video Games**|Jacob Morrier et.al.|[2503.20968](http://arxiv.org/abs/2503.20968)|null|\n", "2503.20119": "|**2025-03-25**|**Approximating Opaque Top-k Queries**|Jiwon Chang et.al.|[2503.20119](http://arxiv.org/abs/2503.20119)|null|\n", "2503.19856": "|**2025-03-25**|**Capacity-Constrained Online Learning with Delays: Scheduling Frameworks and Regret Trade-offs**|Alexander Ryabchenko et.al.|[2503.19856](http://arxiv.org/abs/2503.19856)|null|\n", "2503.19554": "|**2025-03-25**|**Causal Bayesian Optimization with Unknown Graphs**|Jean Durand et.al.|[2503.19554](http://arxiv.org/abs/2503.19554)|null|\n", "2503.19523": "|**2025-03-26**|**One Framework to Rule Them All: Unifying RL-Based and RL-Free Methods in RLHF**|Xin Cai et.al.|[2503.19523](http://arxiv.org/abs/2503.19523)|null|\n", "2503.19390": "|**2025-03-25**|**Integrating Prefetcher Selection with Dynamic Request Allocation Improves Prefetching Efficiency**|Mengming Li et.al.|[2503.19390](http://arxiv.org/abs/2503.19390)|null|\n", "2503.18980": "|**2025-03-23**|**CAE: Repurposing the Critic as an Explorer in Deep Reinforcement Learning**|Yexin Li et.al.|[2503.18980](http://arxiv.org/abs/2503.18980)|null|\n", "2503.22595": "|**2025-03-28**|**Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments**|S. Aaron McClendon et.al.|[2503.22595](http://arxiv.org/abs/2503.22595)|null|\n", "2504.02646": "|**2025-04-03**|**Prompt Optimization with Logged Bandit Data**|Haruka Kiyohara et.al.|[2504.02646](http://arxiv.org/abs/2504.02646)|null|\n", "2504.02251": "|**2025-04-03**|**Quantum Lipschitz Bandits**|Bongsoo Yi et.al.|[2504.02251](http://arxiv.org/abs/2504.02251)|null|\n", "2504.02130": "|**2025-04-02**|**Ordering-based Conditions for Global Convergence of Policy Gradient Methods**|Jincheng Mei et.al.|[2504.02130](http://arxiv.org/abs/2504.02130)|null|\n", "2504.02019": "|**2025-04-02**|**Antithetic Sampling for Top-k Shapley Identification**|Patrick Kolpaczki et.al.|[2504.02019](http://arxiv.org/abs/2504.02019)|null|\n", "2504.00461": "|**2025-04-01**|**Efficient Near-Optimal Algorithm for Online Shortest Paths in Directed Acyclic Graphs with Bandit Feedback Against Adaptive Adversaries**|Arnab Maiti et.al.|[2504.00461](http://arxiv.org/abs/2504.00461)|null|\n", "2504.06820": "|**2025-04-09**|**Regret Bounds for Robust Online Decision Making**|Alexander Appel et.al.|[2504.06820](http://arxiv.org/abs/2504.06820)|null|\n", "2504.05964": "|**2025-04-08**|**Context-aware Rate Adaptation for Predictive Flying Networks using Contextual Bandits**|Ruben Queiros et.al.|[2504.05964](http://arxiv.org/abs/2504.05964)|null|\n", "2504.04916": "|**2025-04-07**|**Age-of-information minimization under energy harvesting and non-stationary environment**|Akanksha Jaiswal et.al.|[2504.04916](http://arxiv.org/abs/2504.04916)|null|\n", "2504.04505": "|**2025-04-06**|**A Classification View on Meta Learning Bandits**|Mirco Mutti et.al.|[2504.04505](http://arxiv.org/abs/2504.04505)|null|\n", "2504.03926": "|**2025-04-04**|**An Exploration-free Method for a Linear Stochastic Bandit Driven by a Linear Gaussian Dynamical System**|Jonathan Gornet et.al.|[2504.03926](http://arxiv.org/abs/2504.03926)|null|\n", "2504.03178": "|**2025-04-04**|**Throughput-Optimal Random Access: A Queueing-Theoretical Analysis for Learning-Based Access Design**|Xinran Zhao et.al.|[2504.03178](http://arxiv.org/abs/2504.03178)|null|\n", "2504.10391": "|**2025-04-14**|**LLM-driven Constrained Copy Generation through Iterative Refinement**|Varun Vasudevan et.al.|[2504.10391](http://arxiv.org/abs/2504.10391)|null|\n", "2504.09353": "|**2025-04-12**|**Breaking the Lens of the Telescope: Online Relevance Estimation over Large Retrieval Sets**|Mandeep Rathee et.al.|[2504.09353](http://arxiv.org/abs/2504.09353)|null|\n", "2504.09192": "|**2025-04-12**|**Towards More Efficient, Robust, Instance-adaptive, and Generalizable Online Learning**|Zhiyong Wang et.al.|[2504.09192](http://arxiv.org/abs/2504.09192)|null|\n", "2504.08331": "|**2025-04-11**|**Scalable Conflict-free Decision Making with Photons**|Kohei Konaka et.al.|[2504.08331](http://arxiv.org/abs/2504.08331)|null|\n", "2504.08200": "|**2025-04-11**|**Influential Bandits: Pulling an Arm May Change the Environment**|Ryoma Sato et.al.|[2504.08200](http://arxiv.org/abs/2504.08200)|null|\n", "2504.07307": "|**2025-04-09**|**Follow-the-Perturbed-Leader Achieves Best-of-Both-Worlds for the m-Set Semi-Bandit Problems**|Jingxin Zhan et.al.|[2504.07307](http://arxiv.org/abs/2504.07307)|null|\n", "2504.12086": "|**2025-04-16**|**Neural Contextual Bandits Under Delayed Feedback Constraints**|Mohammadali Moghimi et.al.|[2504.12086](http://arxiv.org/abs/2504.12086)|null|\n", "2504.12016": "|**2025-04-16**|**Active Human Feedback Collection via Neural Contextual Dueling Bandits**|Arun Verma et.al.|[2504.12016](http://arxiv.org/abs/2504.12016)|null|\n", "2504.11866": "|**2025-04-16**|**On the Problem of Best Arm Retention**|Houshuang Chen et.al.|[2504.11866](http://arxiv.org/abs/2504.11866)|null|\n", "2504.10959": "|**2025-04-15**|**Learning-Based User Association for MmWave Vehicular Networks With Kernelized Contextual Bandits**|Xiaoyang He et.al.|[2504.10959](http://arxiv.org/abs/2504.10959)|null|\n", "2504.10622": "|**2025-04-14**|**Improving Upon the generalized c-mu rule: a Whittle approach**|Zhouzi Li et.al.|[2504.10622](http://arxiv.org/abs/2504.10622)|null|\n", "2504.17277": "|**2025-04-24**|**ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders**|Zongliang Ji et.al.|[2504.17277](http://arxiv.org/abs/2504.17277)|null|\n", "2504.16415": "|**2025-04-23**|**Natural Policy Gradient for Average Reward Non-Stationary RL**|Neharika Jali et.al.|[2504.16415](http://arxiv.org/abs/2504.16415)|null|\n", "2504.16371": "|**2025-04-23**|**The Safety-Privacy Tradeoff in Linear Bandits**|Arghavan Zibaie et.al.|[2504.16371](http://arxiv.org/abs/2504.16371)|null|\n", "2504.16211": "|**2025-04-24**|**One-Point Sampling for Distributed Bandit Convex Optimization with Time-Varying Constraints**|Kunpeng Zhang et.al.|[2504.16211](http://arxiv.org/abs/2504.16211)|null|\n", "2504.16078": "|**2025-04-22**|**LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities**|Thomas Schmied et.al.|[2504.16078](http://arxiv.org/abs/2504.16078)|null|\n", "2504.15812": "|**2025-04-22**|**Fusing Reward and Dueling Feedback in Stochastic Bandits**|Xuchuang Wang et.al.|[2504.15812](http://arxiv.org/abs/2504.15812)|null|\n", "2504.14725": "|**2025-04-20**|**Sensor Scheduling in Intrusion Detection Games with Uncertain Payoffs**|Jayanth Bhargav et.al.|[2504.14725](http://arxiv.org/abs/2504.14725)|null|\n", "2504.14416": "|**2025-04-19**|**Exploring Pseudo-Token Approaches in Transformer Neural Processes**|Jose Lara-Rangel et.al.|[2504.14416](http://arxiv.org/abs/2504.14416)|null|\n", "2504.14085": "|**2025-04-18**|**Access Probability Optimization in RACH: A Multi-Armed Bandits Approach**|Ahmed O. Elmeligy et.al.|[2504.14085](http://arxiv.org/abs/2504.14085)|null|\n"}}