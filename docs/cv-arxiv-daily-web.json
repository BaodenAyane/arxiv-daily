{"Bandits": {"2503.03023": "|**2025-03-04**|**Quantum Non-Linear Bandit Optimization**|Zakaria Shams Siam et.al.|[2503.03023](http://arxiv.org/abs/2503.03023)|null|\n", "2503.02043": "|**2025-03-03**|**Constrained Linear Thompson Sampling**|Aditya Gangrade et.al.|[2503.02043](http://arxiv.org/abs/2503.02043)|null|\n", "2503.00929": "|**2025-03-02**|**Parameter-Adaptive Dynamic Pricing**|Xueping Gong et.al.|[2503.00929](http://arxiv.org/abs/2503.00929)|null|\n", "2503.00565": "|**2025-03-01**|**Semi-Parametric Batched Global Multi-Armed Bandits with Covariates**|Sakshi Arya et.al.|[2503.00565](http://arxiv.org/abs/2503.00565)|null|\n", "2503.00419": "|**2025-03-01**|**Heavy-Tailed Linear Bandits: Huber Regression with One-Pass Update**|Jing Wang et.al.|[2503.00419](http://arxiv.org/abs/2503.00419)|null|\n", "2502.17175": "|**2025-02-24**|**Linear Bandits on Ellipsoids: Minimax Optimal Algorithms**|Raymond Zhang et.al.|[2502.17175](http://arxiv.org/abs/2502.17175)|null|\n", "2502.12528": "|**2025-02-20**|**Contextual Linear Bandits with Delay as Payoff**|Mengxiao Zhang et.al.|[2502.12528](http://arxiv.org/abs/2502.12528)|null|\n", "2502.08870": "|**2025-02-13**|**When and why randomised exploration works (in linear bandits)**|Marc Abeille et.al.|[2502.08870](http://arxiv.org/abs/2502.08870)|null|\n", "2502.07514": "|**2025-02-11**|**A Near-optimal, Scalable and Corruption-tolerant Framework for Stochastic Bandits: From Single-Agent to Multi-Agent and Beyond**|Zicheng Hu et.al.|[2502.07514](http://arxiv.org/abs/2502.07514)|null|\n", "2502.07397": "|**2025-02-11**|**Bandit Optimal Transport**|Lorenzo Croissant et.al.|[2502.07397](http://arxiv.org/abs/2502.07397)|null|\n", "2502.08077": "|**2025-02-12**|**Cascading Bandits Robust to Adversarial Corruptions**|Jize Xie et.al.|[2502.08077](http://arxiv.org/abs/2502.08077)|null|\n", "2503.02952": "|**2025-03-04**|**A Theoretical Model for Grit in Pursuing Ambitious Ends**|Avrim Blum et.al.|[2503.02952](http://arxiv.org/abs/2503.02952)|null|\n", "2503.02735": "|**2025-03-04**|**Clustered KL-barycenter design for policy evaluation**|Simon Weissmann et.al.|[2503.02735](http://arxiv.org/abs/2503.02735)|null|\n", "2503.02428": "|**2025-03-04**|**Tight Gap-Dependent Memory-Regret Trade-Off for Single-Pass Streaming Stochastic Multi-Armed Bandits**|Zichun Ye et.al.|[2503.02428](http://arxiv.org/abs/2503.02428)|null|\n", "2503.01324": "|**2025-03-03**|**MAB-Based Channel Scheduling for Asynchronous Federated Learning in Non-Stationary Environments**|Zhiyin Li et.al.|[2503.01324](http://arxiv.org/abs/2503.01324)|null|\n", "2503.01215": "|**2025-03-03**|**Architectural and Inferential Inductive Biases For Exchangeable Sequence Modeling**|Daksh Mittal et.al.|[2503.01215](http://arxiv.org/abs/2503.01215)|**[link](https://github.com/namkoong-lab/inductive-biases-exchangeable-sequence)**|\n", "2503.01163": "|**2025-03-03**|**Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers**|Rin Ashizawa et.al.|[2503.01163](http://arxiv.org/abs/2503.01163)|null|\n", "2503.01919": "|**2025-03-01**|**Reinforcement learning with combinatorial actions for coupled restless bandits**|Lily Xu et.al.|[2503.01919](http://arxiv.org/abs/2503.01919)|null|\n"}}