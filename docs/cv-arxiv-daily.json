{"Bandits": {"2503.03023": "|**2025-03-04**|**Quantum Non-Linear Bandit Optimization**|Zakaria Shams Siam et.al.|[2503.03023](http://arxiv.org/abs/2503.03023)|null|\n", "2503.02043": "|**2025-03-03**|**Constrained Linear Thompson Sampling**|Aditya Gangrade et.al.|[2503.02043](http://arxiv.org/abs/2503.02043)|null|\n", "2503.00929": "|**2025-03-02**|**Parameter-Adaptive Dynamic Pricing**|Xueping Gong et.al.|[2503.00929](http://arxiv.org/abs/2503.00929)|null|\n", "2503.00565": "|**2025-03-01**|**Semi-Parametric Batched Global Multi-Armed Bandits with Covariates**|Sakshi Arya et.al.|[2503.00565](http://arxiv.org/abs/2503.00565)|null|\n", "2503.00419": "|**2025-03-01**|**Heavy-Tailed Linear Bandits: Huber Regression with One-Pass Update**|Jing Wang et.al.|[2503.00419](http://arxiv.org/abs/2503.00419)|null|\n", "2502.17175": "|**2025-02-24**|**Linear Bandits on Ellipsoids: Minimax Optimal Algorithms**|Raymond Zhang et.al.|[2502.17175](http://arxiv.org/abs/2502.17175)|null|\n", "2502.12528": "|**2025-02-20**|**Contextual Linear Bandits with Delay as Payoff**|Mengxiao Zhang et.al.|[2502.12528](http://arxiv.org/abs/2502.12528)|null|\n", "2502.08870": "|**2025-02-13**|**When and why randomised exploration works (in linear bandits)**|Marc Abeille et.al.|[2502.08870](http://arxiv.org/abs/2502.08870)|null|\n", "2502.07514": "|**2025-02-11**|**A Near-optimal, Scalable and Corruption-tolerant Framework for Stochastic Bandits: From Single-Agent to Multi-Agent and Beyond**|Zicheng Hu et.al.|[2502.07514](http://arxiv.org/abs/2502.07514)|null|\n", "2502.07397": "|**2025-02-11**|**Bandit Optimal Transport**|Lorenzo Croissant et.al.|[2502.07397](http://arxiv.org/abs/2502.07397)|null|\n", "2502.08077": "|**2025-02-12**|**Cascading Bandits Robust to Adversarial Corruptions**|Jize Xie et.al.|[2502.08077](http://arxiv.org/abs/2502.08077)|null|\n", "2503.02952": "|**2025-03-04**|**A Theoretical Model for Grit in Pursuing Ambitious Ends**|Avrim Blum et.al.|[2503.02952](http://arxiv.org/abs/2503.02952)|null|\n", "2503.02735": "|**2025-03-04**|**Clustered KL-barycenter design for policy evaluation**|Simon Weissmann et.al.|[2503.02735](http://arxiv.org/abs/2503.02735)|null|\n", "2503.02428": "|**2025-03-04**|**Tight Gap-Dependent Memory-Regret Trade-Off for Single-Pass Streaming Stochastic Multi-Armed Bandits**|Zichun Ye et.al.|[2503.02428](http://arxiv.org/abs/2503.02428)|null|\n", "2503.01324": "|**2025-03-03**|**MAB-Based Channel Scheduling for Asynchronous Federated Learning in Non-Stationary Environments**|Zhiyin Li et.al.|[2503.01324](http://arxiv.org/abs/2503.01324)|null|\n", "2503.01215": "|**2025-03-03**|**Architectural and Inferential Inductive Biases For Exchangeable Sequence Modeling**|Daksh Mittal et.al.|[2503.01215](http://arxiv.org/abs/2503.01215)|**[link](https://github.com/namkoong-lab/inductive-biases-exchangeable-sequence)**|\n", "2503.01163": "|**2025-03-03**|**Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers**|Rin Ashizawa et.al.|[2503.01163](http://arxiv.org/abs/2503.01163)|null|\n", "2503.01919": "|**2025-03-01**|**Reinforcement learning with combinatorial actions for coupled restless bandits**|Lily Xu et.al.|[2503.01919](http://arxiv.org/abs/2503.01919)|null|\n", "2503.04518": "|**2025-03-06**|**Leveraging priors on distribution functions for multi-arm bandits**|Sumit Vashishtha et.al.|[2503.04518](http://arxiv.org/abs/2503.04518)|null|\n", "2503.04010": "|**2025-03-06**|**Greedy Algorithm for Structured Bandits: A Sharp Characterization of Asymptotic Success / Failure**|Aleksandrs Slivkins et.al.|[2503.04010](http://arxiv.org/abs/2503.04010)|null|\n", "2503.05662": "|**2025-03-07**|**On Mitigating Affinity Bias through Bandits with Evolving Biased Feedback**|Matthew Faw et.al.|[2503.05662](http://arxiv.org/abs/2503.05662)|null|\n", "2503.05098": "|**2025-03-07**|**Empirical Bound Information-Directed Sampling for Norm-Agnostic Bandits**|Piotr M. Suder et.al.|[2503.05098](http://arxiv.org/abs/2503.05098)|null|\n", "2503.04855": "|**2025-03-06**|**A characterization of sample adaptivity in UCB data**|Yilun Chen et.al.|[2503.04855](http://arxiv.org/abs/2503.04855)|null|\n", "2503.08098": "|**2025-03-11**|**Locally Private Nonparametric Contextual Multi-armed Bandits**|Yuheng Ma et.al.|[2503.08098](http://arxiv.org/abs/2503.08098)|**[link](https://github.com/Karlmyh/LDP-Contextual-MAB)**|\n", "2503.08004": "|**2025-03-11**|**Multiplayer Information Asymmetric Bandits in Metric Spaces**|William Chang et.al.|[2503.08004](http://arxiv.org/abs/2503.08004)|null|\n", "2503.07877": "|**2025-03-10**|**Cost-Aware Optimal Pairwise Pure Exploration**|Di Wu et.al.|[2503.07877](http://arxiv.org/abs/2503.07877)|null|\n", "2503.07824": "|**2025-03-10**|**Pure Exploration with Feedback Graphs**|Alessio Russo et.al.|[2503.07824](http://arxiv.org/abs/2503.07824)|**[link](https://github.com/rssalessio/Pure-Exploration-with-Feedback-Graphs)**|\n", "2503.07555": "|**2025-03-10**|**Graph-Dependent Regret Bounds in Multi-Armed Bandits with Interference**|Fateme Jamshidi et.al.|[2503.07555](http://arxiv.org/abs/2503.07555)|null|\n", "2503.06101": "|**2025-03-08**|**ULTHO: Ultra-Lightweight yet Efficient Hyperparameter Optimization in Deep Reinforcement Learning**|Mingqi Yuan et.al.|[2503.06101](http://arxiv.org/abs/2503.06101)|null|\n", "2503.10386": "|**2025-03-14**|**Multi-objective Good Arm Identification with Bandit Feedback**|Xuanke Jiang et.al.|[2503.10386](http://arxiv.org/abs/2503.10386)|**[link](https://github.com/2015211217/MultiThresholdBandit)**|\n", "2503.10282": "|**2025-03-13**|**HyperArm Bandit Optimization: A Novel approach to Hyperparameter Optimization and an Analysis of Bandit Algorithms in Stochastic and Adversarial Settings**|Samih Karroum et.al.|[2503.10282](http://arxiv.org/abs/2503.10282)|null|\n", "2503.09755": "|**2025-03-12**|**Distributionally Robust Multi-Agent Reinforcement Learning for Dynamic Chute Mapping**|Guangyi Liu et.al.|[2503.09755](http://arxiv.org/abs/2503.09755)|null|\n", "2503.08961": "|**2025-03-11**|**Multiplayer Information Asymmetric Contextual Bandits**|William Chang et.al.|[2503.08961](http://arxiv.org/abs/2503.08961)|null|\n", "2503.08937": "|**2025-03-11**|**Beam Selection in ISAC using Contextual Bandit with Multi-modal Transformer and Transfer Learning**|Mohammad Farzanullah et.al.|[2503.08937](http://arxiv.org/abs/2503.08937)|null|\n", "2503.08896": "|**2025-03-11**|**Risk-sensitive Bandits: Arm Mixture Optimality and Regret-efficient Algorithms**|Meltem Tatl\u0131 et.al.|[2503.08896](http://arxiv.org/abs/2503.08896)|**[link](https://github.com/MeltemTatli/Risk-sensitive-Bandits-Arm-Mixture-Optimality)**|\n", "2503.08883": "|**2025-03-11**|**Imitation Learning of Correlated Policies in Stackelberg Games**|Kunag-Da Wang et.al.|[2503.08883](http://arxiv.org/abs/2503.08883)|null|\n", "2503.11209": "|**2025-03-18**|**Clustering Items through Bandit Feedback: Finding the Right Feature out of Many**|Maximilian Graf et.al.|[2503.11209](http://arxiv.org/abs/2503.11209)|null|\n", "2503.10836": "|**2025-03-13**|**Exploiting Concavity Information in Gaussian Process Contextual Bandit Optimization**|Kevin Li et.al.|[2503.10836](http://arxiv.org/abs/2503.10836)|null|\n", "2503.14796": "|**2025-03-19**|**A New Benchmark for Online Learning with Budget-Balancing Constraints**|Mark Braverman et.al.|[2503.14796](http://arxiv.org/abs/2503.14796)|null|\n", "2503.14663": "|**2025-03-18**|**Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction**|Anni Zhou et.al.|[2503.14663](http://arxiv.org/abs/2503.14663)|null|\n", "2503.13447": "|**2025-03-17**|**MetaScale: Test-Time Scaling with Evolving Meta-Thoughts**|Qin Liu et.al.|[2503.13447](http://arxiv.org/abs/2503.13447)|null|\n", "2503.13173": "|**2025-03-17**|**PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning**|Ori Peleg et.al.|[2503.13173](http://arxiv.org/abs/2503.13173)|**[link](https://github.com/oritalp/PAUSE)**|\n", "2503.12285": "|**2025-03-15**|**Bi-Criteria Optimization for Combinatorial Bandits: Sublinear Regret and Constraint Violation under Bandit Feedback**|Vaneet Aggarwal et.al.|[2503.12285](http://arxiv.org/abs/2503.12285)|null|\n", "2503.12020": "|**2025-03-15**|**Variance-Dependent Regret Lower Bounds for Contextual Bandits**|Jiafan He et.al.|[2503.12020](http://arxiv.org/abs/2503.12020)|null|\n", "2503.11991": "|**2025-03-15**|**Automation and Feature Selection Enhancement with Reinforcement Learning (RL)**|Sumana Sanyasipura Nagaraju et.al.|[2503.11991](http://arxiv.org/abs/2503.11991)|null|\n", "2503.16382": "|**2025-03-20**|**Sparse Nonparametric Contextual Bandits**|Hamish Flynn et.al.|[2503.16382](http://arxiv.org/abs/2503.16382)|null|\n", "2503.16107": "|**2025-03-20**|**Learn to Bid as a Price-Maker Wind Power Producer**|Shobhit Singhal et.al.|[2503.16107](http://arxiv.org/abs/2503.16107)|null|\n", "2503.15962": "|**2025-03-20**|**Information maximization for a broad variety of multi-armed bandit games**|Alex Barbier-Chebbah et.al.|[2503.15962](http://arxiv.org/abs/2503.15962)|null|\n", "2503.15581": "|**2025-03-19**|**Performance-bounded Online Ensemble Learning Method Based on Multi-armed bandits and Its Applications in Real-time Safety Assessment**|Songqiao Hu et.al.|[2503.15581](http://arxiv.org/abs/2503.15581)|**[link](https://github.com/liuzy0708/Awesome_OL)**|\n", "2503.18133": "|**2025-03-23**|**Beam Scheduling in Millimeter Wave Networks Using the Whittle Index**|Mandar R. Nalavade et.al.|[2503.18133](http://arxiv.org/abs/2503.18133)|null|\n", "2503.17674": "|**2025-03-22**|**MultiScale Contextual Bandits for Long Term Objectives**|Richa Rastogi et.al.|[2503.17674](http://arxiv.org/abs/2503.17674)|null|\n", "2503.16941": "|**2025-03-21**|**Sparse Additive Contextual Bandits: A Nonparametric Approach for Online Decision-making with High-dimensional Covariates**|Wenjia Wang et.al.|[2503.16941](http://arxiv.org/abs/2503.16941)|null|\n", "2503.16708": "|**2025-03-20**|**NeuroSep-CP-LCB: A Deep Learning-based Contextual Multi-armed Bandit Algorithm with Uncertainty Quantification for Early Sepsis Prediction**|Anni Zhou et.al.|[2503.16708](http://arxiv.org/abs/2503.16708)|null|\n", "2503.21498": "|**2025-03-27**|**Distributed Forgetting-factor Regret-based Online Optimization over Undirected Connected Networks**|Lipo Mo et.al.|[2503.21498](http://arxiv.org/abs/2503.21498)|null|\n", "2503.20975": "|**2025-03-26**|**Competitive Multi-armed Bandit Games for Resource Sharing**|Hongbo Li et.al.|[2503.20975](http://arxiv.org/abs/2503.20975)|null|\n", "2503.20968": "|**2025-03-26**|**Reinforcement Learning for Efficient Toxicity Detection in Competitive Online Video Games**|Jacob Morrier et.al.|[2503.20968](http://arxiv.org/abs/2503.20968)|null|\n", "2503.20119": "|**2025-03-25**|**Approximating Opaque Top-k Queries**|Jiwon Chang et.al.|[2503.20119](http://arxiv.org/abs/2503.20119)|null|\n", "2503.19856": "|**2025-03-25**|**Capacity-Constrained Online Learning with Delays: Scheduling Frameworks and Regret Trade-offs**|Alexander Ryabchenko et.al.|[2503.19856](http://arxiv.org/abs/2503.19856)|null|\n", "2503.19554": "|**2025-03-25**|**Causal Bayesian Optimization with Unknown Graphs**|Jean Durand et.al.|[2503.19554](http://arxiv.org/abs/2503.19554)|null|\n", "2503.19523": "|**2025-03-26**|**One Framework to Rule Them All: Unifying RL-Based and RL-Free Methods in RLHF**|Xin Cai et.al.|[2503.19523](http://arxiv.org/abs/2503.19523)|null|\n", "2503.19390": "|**2025-03-25**|**Integrating Prefetcher Selection with Dynamic Request Allocation Improves Prefetching Efficiency**|Mengming Li et.al.|[2503.19390](http://arxiv.org/abs/2503.19390)|null|\n", "2503.18980": "|**2025-03-23**|**CAE: Repurposing the Critic as an Explorer in Deep Reinforcement Learning**|Yexin Li et.al.|[2503.18980](http://arxiv.org/abs/2503.18980)|null|\n", "2503.22595": "|**2025-03-28**|**Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments**|S. Aaron McClendon et.al.|[2503.22595](http://arxiv.org/abs/2503.22595)|null|\n", "2504.02646": "|**2025-04-03**|**Prompt Optimization with Logged Bandit Data**|Haruka Kiyohara et.al.|[2504.02646](http://arxiv.org/abs/2504.02646)|null|\n", "2504.02251": "|**2025-04-03**|**Quantum Lipschitz Bandits**|Bongsoo Yi et.al.|[2504.02251](http://arxiv.org/abs/2504.02251)|null|\n", "2504.02130": "|**2025-04-02**|**Ordering-based Conditions for Global Convergence of Policy Gradient Methods**|Jincheng Mei et.al.|[2504.02130](http://arxiv.org/abs/2504.02130)|null|\n", "2504.02019": "|**2025-04-02**|**Antithetic Sampling for Top-k Shapley Identification**|Patrick Kolpaczki et.al.|[2504.02019](http://arxiv.org/abs/2504.02019)|null|\n", "2504.00461": "|**2025-04-01**|**Efficient Near-Optimal Algorithm for Online Shortest Paths in Directed Acyclic Graphs with Bandit Feedback Against Adaptive Adversaries**|Arnab Maiti et.al.|[2504.00461](http://arxiv.org/abs/2504.00461)|null|\n", "2504.06820": "|**2025-04-09**|**Regret Bounds for Robust Online Decision Making**|Alexander Appel et.al.|[2504.06820](http://arxiv.org/abs/2504.06820)|null|\n", "2504.05964": "|**2025-04-08**|**Context-aware Rate Adaptation for Predictive Flying Networks using Contextual Bandits**|Ruben Queiros et.al.|[2504.05964](http://arxiv.org/abs/2504.05964)|null|\n", "2504.04916": "|**2025-04-07**|**Age-of-information minimization under energy harvesting and non-stationary environment**|Akanksha Jaiswal et.al.|[2504.04916](http://arxiv.org/abs/2504.04916)|null|\n", "2504.04505": "|**2025-04-06**|**A Classification View on Meta Learning Bandits**|Mirco Mutti et.al.|[2504.04505](http://arxiv.org/abs/2504.04505)|null|\n", "2504.03926": "|**2025-04-04**|**An Exploration-free Method for a Linear Stochastic Bandit Driven by a Linear Gaussian Dynamical System**|Jonathan Gornet et.al.|[2504.03926](http://arxiv.org/abs/2504.03926)|null|\n", "2504.03178": "|**2025-04-04**|**Throughput-Optimal Random Access: A Queueing-Theoretical Analysis for Learning-Based Access Design**|Xinran Zhao et.al.|[2504.03178](http://arxiv.org/abs/2504.03178)|null|\n", "2504.10391": "|**2025-04-14**|**LLM-driven Constrained Copy Generation through Iterative Refinement**|Varun Vasudevan et.al.|[2504.10391](http://arxiv.org/abs/2504.10391)|null|\n", "2504.09353": "|**2025-04-12**|**Breaking the Lens of the Telescope: Online Relevance Estimation over Large Retrieval Sets**|Mandeep Rathee et.al.|[2504.09353](http://arxiv.org/abs/2504.09353)|null|\n", "2504.09192": "|**2025-04-12**|**Towards More Efficient, Robust, Instance-adaptive, and Generalizable Online Learning**|Zhiyong Wang et.al.|[2504.09192](http://arxiv.org/abs/2504.09192)|null|\n", "2504.08331": "|**2025-04-11**|**Scalable Conflict-free Decision Making with Photons**|Kohei Konaka et.al.|[2504.08331](http://arxiv.org/abs/2504.08331)|null|\n", "2504.08200": "|**2025-04-11**|**Influential Bandits: Pulling an Arm May Change the Environment**|Ryoma Sato et.al.|[2504.08200](http://arxiv.org/abs/2504.08200)|null|\n", "2504.07307": "|**2025-04-09**|**Follow-the-Perturbed-Leader Achieves Best-of-Both-Worlds for the m-Set Semi-Bandit Problems**|Jingxin Zhan et.al.|[2504.07307](http://arxiv.org/abs/2504.07307)|null|\n", "2504.12086": "|**2025-04-16**|**Neural Contextual Bandits Under Delayed Feedback Constraints**|Mohammadali Moghimi et.al.|[2504.12086](http://arxiv.org/abs/2504.12086)|null|\n", "2504.12016": "|**2025-04-16**|**Active Human Feedback Collection via Neural Contextual Dueling Bandits**|Arun Verma et.al.|[2504.12016](http://arxiv.org/abs/2504.12016)|null|\n", "2504.11866": "|**2025-04-16**|**On the Problem of Best Arm Retention**|Houshuang Chen et.al.|[2504.11866](http://arxiv.org/abs/2504.11866)|null|\n", "2504.10959": "|**2025-04-15**|**Learning-Based User Association for MmWave Vehicular Networks With Kernelized Contextual Bandits**|Xiaoyang He et.al.|[2504.10959](http://arxiv.org/abs/2504.10959)|null|\n", "2504.10622": "|**2025-04-14**|**Improving Upon the generalized c-mu rule: a Whittle approach**|Zhouzi Li et.al.|[2504.10622](http://arxiv.org/abs/2504.10622)|null|\n", "2504.17277": "|**2025-04-24**|**ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders**|Zongliang Ji et.al.|[2504.17277](http://arxiv.org/abs/2504.17277)|null|\n", "2504.16415": "|**2025-04-23**|**Natural Policy Gradient for Average Reward Non-Stationary RL**|Neharika Jali et.al.|[2504.16415](http://arxiv.org/abs/2504.16415)|null|\n", "2504.16371": "|**2025-04-23**|**The Safety-Privacy Tradeoff in Linear Bandits**|Arghavan Zibaie et.al.|[2504.16371](http://arxiv.org/abs/2504.16371)|null|\n", "2504.16211": "|**2025-04-24**|**One-Point Sampling for Distributed Bandit Convex Optimization with Time-Varying Constraints**|Kunpeng Zhang et.al.|[2504.16211](http://arxiv.org/abs/2504.16211)|null|\n", "2504.16078": "|**2025-04-22**|**LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities**|Thomas Schmied et.al.|[2504.16078](http://arxiv.org/abs/2504.16078)|null|\n", "2504.15812": "|**2025-04-22**|**Fusing Reward and Dueling Feedback in Stochastic Bandits**|Xuchuang Wang et.al.|[2504.15812](http://arxiv.org/abs/2504.15812)|null|\n", "2504.14725": "|**2025-04-20**|**Sensor Scheduling in Intrusion Detection Games with Uncertain Payoffs**|Jayanth Bhargav et.al.|[2504.14725](http://arxiv.org/abs/2504.14725)|null|\n", "2504.14416": "|**2025-04-19**|**Exploring Pseudo-Token Approaches in Transformer Neural Processes**|Jose Lara-Rangel et.al.|[2504.14416](http://arxiv.org/abs/2504.14416)|null|\n", "2504.14085": "|**2025-04-18**|**Access Probability Optimization in RACH: A Multi-Armed Bandits Approach**|Ahmed O. Elmeligy et.al.|[2504.14085](http://arxiv.org/abs/2504.14085)|null|\n", "2504.20894": "|**2025-04-29**|**Does Feedback Help in Bandits with Arm Erasures?**|Merve Karakas et.al.|[2504.20894](http://arxiv.org/abs/2504.20894)|null|\n", "2504.20877": "|**2025-04-30**|**Preference-centric Bandits: Optimality of Mixtures and Regret-efficient Algorithms**|Meltem Tatl\u0131 et.al.|[2504.20877](http://arxiv.org/abs/2504.20877)|null|\n", "2504.18375": "|**2025-04-25**|**Bandit on the Hunt: Dynamic Crawling for Cyber Threat Intelligence**|Philipp Kuehn et.al.|[2504.18375](http://arxiv.org/abs/2504.18375)|null|\n", "2504.18031": "|**2025-04-25**|**Joint Resource Estimation and Trajectory Optimization for eVTOL-involved CR network: A Monte Carlo Tree Search-based Approach**|Kai Xiong et.al.|[2504.18031](http://arxiv.org/abs/2504.18031)|null|\n", "2505.00961": "|**2025-05-02**|**DOLCE: Decomposing Off-Policy Evaluation/Learning into Lagged and Current Effects**|Shu Tamano et.al.|[2505.00961](http://arxiv.org/abs/2505.00961)|null|\n", "2504.21693": "|**2025-05-04**|**Distributed Online Randomized Gradient-Free optimization with Compressed Communication**|Longkang Zhu et.al.|[2504.21693](http://arxiv.org/abs/2504.21693)|null|\n", "2505.05226": "|**2025-05-08**|**Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning**|Amir Rezaei Balef et.al.|[2505.05226](http://arxiv.org/abs/2505.05226)|null|\n", "2505.05169": "|**2025-05-08**|**Bandit Max-Min Fair Allocation**|Tsubasa Harada et.al.|[2505.05169](http://arxiv.org/abs/2505.05169)|null|\n", "2505.05014": "|**2025-05-08**|**Sample Complexity of Identifying the Nonredundancy of Nontransitive Games in Dueling Bandits**|Shang Lu et.al.|[2505.05014](http://arxiv.org/abs/2505.05014)|null|\n", "2505.04200": "|**2025-05-07**|**Estimating Causal Effects in Networks with Cluster-Based Bandits**|Ahmed Sayeed Faruk et.al.|[2505.04200](http://arxiv.org/abs/2505.04200)|null|\n", "2505.03155": "|**2025-05-06**|**Rethinking the Global Convergence of Softmax Policy Gradient with Linear Function Approximation**|Max Qiushi Lin et.al.|[2505.03155](http://arxiv.org/abs/2505.03155)|null|\n", "2505.02640": "|**2025-05-05**|**Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints**|Shubham Vaishnav et.al.|[2505.02640](http://arxiv.org/abs/2505.02640)|null|\n", "2505.02383": "|**2025-05-05**|**Connecting Thompson Sampling and UCB: Towards More Efficient Trade-offs Between Privacy and Regret**|Bingshan Hu et.al.|[2505.02383](http://arxiv.org/abs/2505.02383)|null|\n", "2505.03840": "|**2025-05-05**|**CoCoB: Adaptive Collaborative Combinatorial Bandits for Online Recommendation**|Cairong Yan et.al.|[2505.03840](http://arxiv.org/abs/2505.03840)|null|\n", "2505.02069": "|**2025-05-04**|**Neural Logistic Bandits**|Seoungbin Bae et.al.|[2505.02069](http://arxiv.org/abs/2505.02069)|null|\n", "2505.01859": "|**2025-05-03**|**Bayesian learning of the optimal action-value function in a Markov decision process**|Jiaqi Guo et.al.|[2505.01859](http://arxiv.org/abs/2505.01859)|null|\n", "2505.08592": "|**2025-05-14**|**Communication-Efficient Distributed Online Nonconvex Optimization with Time-Varying Constraints**|Kunpeng Zhang et.al.|[2505.08592](http://arxiv.org/abs/2505.08592)|null|\n", "2505.08049": "|**2025-05-12**|**Bias or Optimality? Disentangling Bayesian Inference and Learning Biases in Human Decision-Making**|Prakhar Godara et.al.|[2505.08049](http://arxiv.org/abs/2505.08049)|null|\n", "2505.08032": "|**2025-05-12**|**Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience**|Seyed Bagher Hashemi Natanzi et.al.|[2505.08032](http://arxiv.org/abs/2505.08032)|null|\n", "2505.07437": "|**2025-05-12**|**LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning**|Xiaotian Lin et.al.|[2505.07437](http://arxiv.org/abs/2505.07437)|**[link](https://github.com/HKUSTDial/LEAD)**|\n", "2505.07367": "|**2025-05-12**|**Generalization Bounds and Stopping Rules for Learning with Self-Selected Data**|Julian Rodemann et.al.|[2505.07367](http://arxiv.org/abs/2505.07367)|null|\n", "2505.07303": "|**2025-05-12**|**Online Episodic Convex Reinforcement Learning**|Bianca Marin Moreno et.al.|[2505.07303](http://arxiv.org/abs/2505.07303)|null|\n", "2505.07278": "|**2025-05-13**|**Coordinated Spatial Reuse Scheduling With Machine Learning in IEEE 802.11 MAPC Networks**|Maksymilian Wojnar et.al.|[2505.07278](http://arxiv.org/abs/2505.07278)|**[link](https://github.com/ml4wifi-devs/csr)**|\n", "2505.07267": "|**2025-05-12**|**Adaptive, Robust and Scalable Bayesian Filtering for Online Learning**|Gerardo Duran-Martin et.al.|[2505.07267](http://arxiv.org/abs/2505.07267)|null|\n", "2505.07101": "|**2025-05-11**|**Constrained Online Decision-Making with Density Estimation Oracles**|Haichen Hu et.al.|[2505.07101](http://arxiv.org/abs/2505.07101)|null|\n", "2505.07100": "|**2025-05-11**|**Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users**|Julian Rosenberger et.al.|[2505.07100](http://arxiv.org/abs/2505.07100)|null|\n", "2505.13355": "|**2025-05-19**|**Multi-Armed Bandits Meet Large Language Models**|Djallel Bouneffouf et.al.|[2505.13355](http://arxiv.org/abs/2505.13355)|null|\n", "2505.13331": "|**2025-05-19**|**Learning Driven Elastic Task Multi-Connectivity Immersive Computing Systems**|Babak Badnava et.al.|[2505.13331](http://arxiv.org/abs/2505.13331)|null|\n", "2505.13195": "|**2025-05-19**|**Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities**|Lili Zhang et.al.|[2505.13195](http://arxiv.org/abs/2505.13195)|null|\n", "2505.12250": "|**2025-05-18**|**Not All Documents Are What You Need for Extracting Instruction Tuning Data**|Chi Zhang et.al.|[2505.12250](http://arxiv.org/abs/2505.12250)|null|\n", "2505.12092": "|**2025-05-20**|**Thompson Sampling-like Algorithms for Stochastic Rising Bandits**|Marco Fiandri et.al.|[2505.12092](http://arxiv.org/abs/2505.12092)|null|\n", "2505.11821": "|**2025-05-17**|**Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment**|Siliang Zeng et.al.|[2505.11821](http://arxiv.org/abs/2505.11821)|null|\n", "2505.10747": "|**2025-05-15**|**Assumption-lean weak limits and tests for two-stage adaptive experiments**|Ziang Niu et.al.|[2505.10747](http://arxiv.org/abs/2505.10747)|null|\n", "2505.10698": "|**2025-05-15**|**Asymptotically-Optimal Gaussian Bandits with Side Observations**|Alexia Atsidakou et.al.|[2505.10698](http://arxiv.org/abs/2505.10698)|null|\n", "2505.10498": "|**2025-05-15**|**Batched Nonparametric Bandits via k-Nearest Neighbor UCB**|Sakshi Arya et.al.|[2505.10498](http://arxiv.org/abs/2505.10498)|null|\n", "2505.10147": "|**2025-05-15**|**Near Optimal Best Arm Identification for Clustered Bandits**|Yash et.al.|[2505.10147](http://arxiv.org/abs/2505.10147)|null|\n", "2505.16918": "|**2025-05-22**|**Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype**|Nikola Tankovic et.al.|[2505.16918](http://arxiv.org/abs/2505.16918)|null|\n", "2505.16311": "|**2025-05-22**|**Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions**|Marc Brooks et.al.|[2505.16311](http://arxiv.org/abs/2505.16311)|null|\n", "2505.15754": "|**2025-05-21**|**Improving planning and MBRL with temporally-extended actions**|Palash Chatterjee et.al.|[2505.15754](http://arxiv.org/abs/2505.15754)|null|\n", "2505.15643": "|**2025-05-21**|**Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima**|Lan V. Truong et.al.|[2505.15643](http://arxiv.org/abs/2505.15643)|null|\n", "2505.15354": "|**2025-05-21**|**Human in the Loop Adaptive Optimization for Improved Time Series Forecasting**|Malik Tiomoko et.al.|[2505.15354](http://arxiv.org/abs/2505.15354)|**[link](https://github.com/posttraining/post_training)**|\n", "2505.15155": "|**2025-05-21**|**R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization**|Yuante Li et.al.|[2505.15155](http://arxiv.org/abs/2505.15155)|**[link](https://github.com/microsoft/qlib)**|\n", "2505.15862": "|**2025-05-21**|**Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems**|Long Wanga et.al.|[2505.15862](http://arxiv.org/abs/2505.15862)|null|\n", "2505.15141": "|**2025-05-21**|**BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms**|Yunlong Hou et.al.|[2505.15141](http://arxiv.org/abs/2505.15141)|null|\n", "2505.15069": "|**2025-05-21**|**In-Domain African Languages Translation Using LLMs and Multi-armed Bandits**|Pratik Rakesh Singh et.al.|[2505.15069](http://arxiv.org/abs/2505.15069)|null|\n", "2505.14970": "|**2025-05-20**|**Self-Evolving Curriculum for LLM Reasoning**|Xiaoyin Chen et.al.|[2505.14970](http://arxiv.org/abs/2505.14970)|null|\n", "2505.23720": "|**2025-05-29**|**COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents**|Arun Verma et.al.|[2505.23720](http://arxiv.org/abs/2505.23720)|null|\n", "2505.23518": "|**2025-05-29**|**TRAP: Targeted Redirecting of Agentic Preferences**|Hangoo Kang et.al.|[2505.23518](http://arxiv.org/abs/2505.23518)|null|\n", "2505.23436": "|**2025-05-29**|**Emergent Risk Awareness in Rational Agents under Resource Constraints**|Daniel Jarne Ornia et.al.|[2505.23436](http://arxiv.org/abs/2505.23436)|null|\n", "2505.22473": "|**2025-05-28**|**Pure Exploration with Infinite Answers**|Riccardo Poiani et.al.|[2505.22473](http://arxiv.org/abs/2505.22473)|null|\n", "2505.22361": "|**2025-05-28**|**Continuum-armed Bandit Optimization with Batch Pairwise Comparison Oracles**|Xiangyu Chang et.al.|[2505.22361](http://arxiv.org/abs/2505.22361)|null|\n", "2505.21938": "|**2025-05-28**|**Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection**|Qirun Zeng et.al.|[2505.21938](http://arxiv.org/abs/2505.21938)|null|\n", "2505.21790": "|**2025-05-27**|**Faster Rates for Private Adversarial Bandits**|Hilal Asi et.al.|[2505.21790](http://arxiv.org/abs/2505.21790)|null|\n", "2505.21393": "|**2025-05-27**|**Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits**|Maoli Liu et.al.|[2505.21393](http://arxiv.org/abs/2505.21393)|null|\n", "2505.21372": "|**2025-05-27**|**Improving LLM-based Global Optimization with Search Space Partitioning**|Andrej Schwanke et.al.|[2505.21372](http://arxiv.org/abs/2505.21372)|null|\n", "2505.21165": "|**2025-05-27**|**Counterfactual Multi-player Bandits for Explainable Recommendation Diversification**|Yansen Zhang et.al.|[2505.21165](http://arxiv.org/abs/2505.21165)|**[link](https://github.com/forrest-stone/cmb)**|\n", "2506.03802": "|**2025-06-04**|**Learning Equilibria in Matching Games with Bandit Feedback**|Andreas Athanasopoulos et.al.|[2506.03802](http://arxiv.org/abs/2506.03802)|null|\n", "2506.03464": "|**2025-06-04**|**From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications**|Yang Cai et.al.|[2506.03464](http://arxiv.org/abs/2506.03464)|null|\n", "2506.03074": "|**2025-06-04**|**GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression**|Junghyun Lee et.al.|[2506.03074](http://arxiv.org/abs/2506.03074)|null|\n", "2506.02980": "|**2025-06-03**|**Non-stationary Bandit Convex Optimization: A Comprehensive Study**|Xiaoqi Liu et.al.|[2506.02980](http://arxiv.org/abs/2506.02980)|null|\n", "2506.02933": "|**2025-06-03**|**From Theory to Practice with RAVEN-UCB: Addressing Non-Stationarity in Multi-Armed Bandits through Variance Adaptation**|Junyi Fang et.al.|[2506.02933](http://arxiv.org/abs/2506.02933)|**[link](https://github.com/66661654/Raven-UCB)**|\n", "2506.02881": "|**2025-06-03**|**Simulation-Based Inference for Adaptive Experiments**|Brian M Cho et.al.|[2506.02881](http://arxiv.org/abs/2506.02881)|null|\n", "2506.02386": "|**2025-06-03**|**Asymptotically Optimal Linear Best Feasible Arm Identification with Fixed Budget**|Jie Bian et.al.|[2506.02386](http://arxiv.org/abs/2506.02386)|null|\n", "2506.02385": "|**2025-06-03**|**Multi-agent Markov Entanglement**|Shuze Chen et.al.|[2506.02385](http://arxiv.org/abs/2506.02385)|null|\n", "2506.01685": "|**2025-06-02**|**Geometry Meets Incentives: Sample-Efficient Incentivized Exploration with Linear Contexts**|Benjamin Schiffer et.al.|[2506.01685](http://arxiv.org/abs/2506.01685)|null|\n", "2506.01625": "|**2025-06-02**|**Robust Satisficing Gaussian Process Bandits Under Adversarial Attacks**|Artun Saday et.al.|[2506.01625](http://arxiv.org/abs/2506.01625)|null|\n", "2506.07276": "|**2025-06-08**|**Tokenized Bandit for LLM Decoding and Alignment**|Suho Shin et.al.|[2506.07276](http://arxiv.org/abs/2506.07276)|null|\n", "2506.07275": "|**2025-06-08**|**Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models**|Haochen Song et.al.|[2506.07275](http://arxiv.org/abs/2506.07275)|null|\n", "2506.06978": "|**2025-06-08**|**Near Optimal Non-asymptotic Sample Complexity of 1-Identification**|Zitian Li et.al.|[2506.06978](http://arxiv.org/abs/2506.06978)|null|\n", "2506.06891": "|**2025-06-07**|**Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?**|Paulius Sasnauskas et.al.|[2506.06891](http://arxiv.org/abs/2506.06891)|null|\n", "2506.06873": "|**2025-06-07**|**Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning**|Armin Behnamnia et.al.|[2506.06873](http://arxiv.org/abs/2506.06873)|null|\n", "2506.05798": "|**2025-06-06**|**Stochastic modeling of deterministic laser chaos using generator extended dynamic mode decomposition**|Kakutaro Fukushi et.al.|[2506.05798](http://arxiv.org/abs/2506.05798)|null|\n", "2506.05479": "|**2025-06-05**|**Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors**|Matei Gabriel Co\u015fa et.al.|[2506.05479](http://arxiv.org/abs/2506.05479)|null|\n", "2506.05265": "|**2025-06-06**|**Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams**|Mohammed Almutairi et.al.|[2506.05265](http://arxiv.org/abs/2506.05265)|null|\n", "2506.04775": "|**2025-06-05**|**Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards**|Artin Tajdini et.al.|[2506.04775](http://arxiv.org/abs/2506.04775)|null|\n", "2506.04594": "|**2025-06-05**|**Intelligent Channel Allocation for IEEE 802.11be Multi-Link Operation: When MAB Meets LLM**|Shumin Lian et.al.|[2506.04594](http://arxiv.org/abs/2506.04594)|**[link](https://github.com/lianshumin576/mloandmcts)**|\n", "2506.10874": "|**2025-06-12**|**Higher-Order Uncoupled Learning Dynamics and Nash Equilibrium**|Sarah A. Toonsi et.al.|[2506.10874](http://arxiv.org/abs/2506.10874)|null|\n", "2506.10872": "|**2025-06-12**|**The Gittins Index: A Design Principle for Decision-Making Under Uncertainty**|Ziv Scully et.al.|[2506.10872](http://arxiv.org/abs/2506.10872)|null|\n", "2506.10355": "|**2025-06-12**|**TreeLoRA: Efficient Continual Learning via Layer-Wise LoRAs Guided by a Hierarchical Gradient-Similarity Tree**|Yu-Yang Qian et.al.|[2506.10355](http://arxiv.org/abs/2506.10355)|null|\n", "2506.10313": "|**2025-06-12**|**Collaborative Min-Max Regret in Grouped Multi-Armed Bandits**|Mo\u00efse Blanchard et.al.|[2506.10313](http://arxiv.org/abs/2506.10313)|null|\n", "2506.10288": "|**2025-06-12**|**ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs**|Zige Wang et.al.|[2506.10288](http://arxiv.org/abs/2506.10288)|null|\n", "2506.10279": "|**2025-06-12**|**Learning Safe Control via On-the-Fly Bandit Exploration**|Alexandre Capone et.al.|[2506.10279](http://arxiv.org/abs/2506.10279)|null|\n", "2506.10127": "|**2025-06-11**|**Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms**|Xinyi Hu et.al.|[2506.10127](http://arxiv.org/abs/2506.10127)|null|\n", "2506.10091": "|**2025-06-11**|**Efficient kernelized bandit algorithms via exploration distributions**|Bingshan Hu et.al.|[2506.10091](http://arxiv.org/abs/2506.10091)|null|\n", "2506.09270": "|**2025-06-10**|**Uncertainty Prioritized Experience Replay**|Rodrigo Carrasco-Davis et.al.|[2506.09270](http://arxiv.org/abs/2506.09270)|null|\n", "2506.09268": "|**2025-06-10**|**A Multi-Armed Bandit Framework for Online Optimisation in Green Integrated Terrestrial and Non-Terrestrial Networks**|Henri Alam et.al.|[2506.09268](http://arxiv.org/abs/2506.09268)|null|\n"}}